{
 "cells": [
  {
   "cell_type": "raw",
   "id": "constitutional-clock",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "#| default_exp ml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import HTML\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glycowork.ml.models import *\n",
    "from glycowork.ml.inference import *\n",
    "from glycowork.ml.processing import *\n",
    "from glycowork.ml.model_training import *\n",
    "from glycowork.ml.train_test_split import *\n",
    "from glycowork.glycan_data.loader import df_species, df_glycan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-taxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.9241952232606438\n"
     ]
    }
   ],
   "source": [
    "human = [1 if k == 'Homo_sapiens' else 0 for k in df_species[df_species.Order=='Primates'].Species.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Order=='Primates'].target.values.tolist(), human)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['exhaustive'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.9866199493408203),\n",
       " ('Fuc(a1-2)Gal(b1-3)[Neu5Ac(a2-6)]GalNAc', 0.48270383477211),\n",
       " ('Neu5Ac(a2-6)Gal(b1-4)GlcNAc6S(b1-3)Gal(b1-4)[Fuc(a1-3)]Glc-ol',\n",
       "  0.18795396387577057),\n",
       " ('Neu5Ac(a2-3)Gal(b1-3)GalNAc', 0.9019374251365662),\n",
       " ('Glc1Cer', 0.6334248185157776),\n",
       " ('GalNAc(b1-4)Gal(b1-4)Glc1Cer', 0.7008790373802185),\n",
       " ('Neu5Ac(a2-?)Gal(b1-3)GalNAc', 0.904780387878418),\n",
       " ('Gal(b1-3)[Neu5Ac(a2-6)]GalNAc(b1-4)Gal(b1-4)Glc1Cer', 0.4034663736820221),\n",
       " ('Fuc(a1-2)Gal(b1-3)GlcNAc(b1-3)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-6)]Gal(b1-4)Glc-ol',\n",
       "  0.35024815797805786),\n",
       " ('Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-?)[Gal(b1-4)GlcNAc(b1-2)Man(a1-?)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.927925169467926)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-closer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-effect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Galf(b1-1)Man6P-ol(6-3)[Glc(a1-2)]Gal(b1-3)Galf5Ac6Ac(b1-3)Glc(b1-6)Galf', 'Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Man(a1-3)[Man(a1-6)]Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'ManOPOMe(a1-2)Man(a1-2)Man(a1-3)Man', 'Neu5Ac(a2-3)Gal(b1-3)GlcNAc(b1-3)Gal(b1-3)GlcNAc(b1-3)Gal(b1-4)Glc1Cer', 'Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-3)Man(a1-3)[Man(a1-3)[Man(a1-6)]Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-?)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-?)]Man(a1-?)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-?)[Gal(b1-4)GlcNAc(b1-?)]Man(a1-?)]Man(b1-4)GlcNAc(b1-4)GlcNAc', '[GalALys(a1-4)]GalNAc(b1-4)GlcA(b1-3)GlcNAc(b1-6)GalNAc', 'Neu5Ac(a2-3)Gal(b1-3)[Neu5Ac(a2-6)]GlcNAc(b1-4)[GlcNAc(b1-2)]Man(a1-3)[GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', '{Gal(b1-4)GlcNAc(b1-?)}{Gal(b1-4)GlcNAc(b1-?)}{Gal(b1-4)GlcNAc(b1-?)}{Fuc(a1-?)}{Neu5Ac(a2-?)}{Neu5Ac(a2-?)}{Neu5Ac(a2-?)}Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-6)]Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(a1-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[GlcNAc(b1-2)Man(a1-6)][Xyl(b1-2)]Man(b1-4)GlcNAc(b1-4)GlcNAc']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(b1-4)GlcNAc', 'GalA(a1-3)Glc(a1-5)Kdo', '[Man(a1-2)Man(a1-2)Man(a1-2)]Man(a1-6)Man', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAcOS(b1-2)Man(a1-3)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'HexNAc(?1-?)[Fuc(a1-?)]GlcNAc(b1-2)Man(a1-3)[Fuc(a1-?)[HexNAc(?1-?)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'ManNAc(a1-3)Gal(b1-4)LDManHep(a1-5)KdoOP', 'GalNAc(a1-3)[GlcNAc(a1-4)]GalNAc(a1-4)Glc(a1-4)Gal(b1-3)GalNAc', 'Gal(b1-?)GlcNAc(b1-6)[GlcNAc(b1-3)]GalNAc', 'Glc(b1-4)Glc(b1-4)Glc(b1-3)Gal']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.target.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-joyce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
