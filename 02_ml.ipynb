{
 "cells": [
  {
   "cell_type": "raw",
   "id": "constitutional-clock",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "#| default_exp ml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import HTML\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glycowork.ml.models import *\n",
    "from glycowork.ml.inference import *\n",
    "from glycowork.ml.processing import *\n",
    "from glycowork.ml.model_training import *\n",
    "from glycowork.ml.train_test_split import *\n",
    "from glycowork.glycan_data.loader import df_species, df_glycan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-taxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "[05:45:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.8764614185502728\n"
     ]
    }
   ],
   "source": [
    "mammal = [1 if k == 'Mammalia' else 0 for k in df_species[df_species.Phylum=='Chordata'].Class.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Phylum=='Chordata'].target.values.tolist(), mammal)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['exhaustive'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neu5Gc(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[Fuc(a1-3)[GalNAc(b1-4)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8892707228660583),\n",
       " ('Gal(?1-?)[Gal(?1-?)]Gal(b1-4)GlcNAc(b1-2)[GlcNAc(b1-4)]Man(a1-3)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.5475832223892212),\n",
       " ('Man(a1-?)Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 0.8811625242233276),\n",
       " ('GalNAc(?1-?)[Fuc(a1-?)]GlcNAc', 0.6680660247802734),\n",
       " ('Neu5Ac(a2-3)Gal(b1-3)[GlcNAc(b1-6)]GalNAc-ol', 0.8319388031959534),\n",
       " ('Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.8121320605278015),\n",
       " ('GlcA(b1-3)GalNAc6S(b1-4)GlcA(b1-3)GalNAc4S', 0.5543389916419983),\n",
       " ('Neu5Ac(a2-?)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-?)[Fuc(a1-3)[Gal(b1-4)]GlcNAc(b1-2)Man(a1-?)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8300778865814209),\n",
       " ('Fuc(a1-2)[Gal(a1-3)]Gal(b1-3)GalNAc(b1-4)[Neu5Ac(a2-3)]Gal(b1-4)Glc1Cer',\n",
       "  0.7285283803939819),\n",
       " ('Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.7863385677337646)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-closer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-effect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MurNAc(a1-3)L-QuiNAc(a1-3)GlcNAc(b1-4)MurNAc', 'HexNAc(?1-?)[Fuc(a1-?)]HexNAc(?1-?)Gal(?1-?)GalNAc(a1-3)[Neu5Ac(a2-6)]GalNAc', 'LDManHep(a1-3)LDManHepOPPEtN(a1-5)Kdo(a2-8)[KdoOPEtN(a2-4)]Kdo', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)[Gal(a1-4)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Gal(a1-4)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-6)]Man(a1-6)[Gal(b1-4)GlcNAc(b1-4)[Gal(b1-4)GlcNAc(b1-6)]Man(a1-3)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)Glc(b1-4)LDManHep', 'Glc(b1-3)[Glc(b1-6)]Glc', 'Man(a1-3)Man(a1-6)[Xyl(b1-2)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-3)]GlcNAc', 'D-Araf(a1-2)[D-Araf(a1-3)][D-Araf(a1-5)]D-Araf(a1-5)D-Araf', 'GlcNAc6Aep(b1-2)Man(a1-3)[Man6Aep(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Galf(b1-3)Gal(a1-4)Neu5Ac(a2-3)Gal(b1-4)Glc', 'Neu5Gc(a2-?)Gal(b1-?)GalNAc(b1-4)[Neu5Ac(a2-8)Neu5Ac(a2-?)]Gal(b1-4)Glc1Cer', 'Neu5Ac(a2-8)Neu5Ac(a2-3)Gal(b1-3)[Neu5Ac(a2-8)Neu5Ac(a2-6)]GalNAc(b1-4)Gal(b1-4)Glc1Cer', 'Man(a1-2)Man(a1-2)Man', 'Gal(b1-4)GlcNAc(b1-3)[Fuc(a1-3)[Gal(b1-4)]GlcNAc(b1-6)]GalNAc', 'Gal(b1-?)GlcNAc(b1-3)Gal(b1-?)[Fuc(a1-?)]GlcNAc(b1-3)Gal(b1-4)Glc-ol', 'Man(a1-2)Man6PEtN(a1-2)Man(a1-6)[GalNAc(b1-4)]Man2PEtN(a1-4)GlcN', 'Neu5Ac(a2-8)Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[Neu5Ac(a2-8)Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'GlcN(a1-6)GlcNAc', 'Man(a1-2)Man(a1-3)Man(a1-3)[Man(a1-2)Man(a1-3)[Man(a1-2)Man(a1-6)]Man(a1-6)]Man(b1-4)GlcNAc']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.target.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-joyce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
