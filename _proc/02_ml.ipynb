{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indie-confirmation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-brighton",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generic-taxation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bored-quality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.881619937694704\n"
     ]
    }
   ],
   "source": [
    "human = [1 if k == 'Homo_sapiens' else 0 for k in df_species[df_species.Order=='Primates'].Species.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Order=='Primates'].target.values.tolist(), human)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['terminal'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "federal-lover",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEYCAYAAACDV/v0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsU0lEQVR4nO3dd7gkVYH+8e9LjkMQRSQIjGAkSBIEFQxrQgVRF3QRVJKisrrmlaT+VhbTqpgGUMHAKrAKGBAEREHSkDEgOUeJkgTm/f1xqmd6mnv7NjPTVXX7vp/n6ed2V3V3vbdu33P6VJ06R7aJiIio00JNB4iIiKknlU9ERNQulU9ERNQulU9ERNQulU9ERNQulU9ERNQulU9ERNQulU+0kqRrJT0k6R9dt2csgPd85YLKOMD2DpD0w7q214+kXSWd0XSOiI5UPtFmb7C9TNft5ibDSFqkye3Pq8maO0ZbKp+YVCQtJ+lwSbdIuknS5yQtXK2bLulUSX+XdKekH0lavlr3A2AN4ISqFfUxSVtLurHn/We3jqqWyzGSfijpPmDXftsfILslvU/SFZLul/TZKvMfJd0n6aeSFqueu7WkGyV9qvpdrpX0jp79cKSkOyRdJ+nTkhaq1u0q6UxJX5H0d+AnwLeBLarf/Z7qea+XdGG17RskHdD1/mtWeXeRdH2V4T+71i9cZbuq+l3Ol7R6te45kk6WdJekyyW97Un9kWNKSOUTk833gceAZwEvBP4F2K1aJ+DzwDOA5wKrAwcA2N4ZuJ45ramDB9zem4BjgOWBH02w/UG8GtgY2Bz4GDAD+Lcq6wuAnbqe+3RgJWBVYBdghqRnV+u+DiwHrA28DHgn8K6u174IuBpYuXr/vYCzqt99+eo5D1SvWx54PfBeSdv15N0KeDbwCmA/Sc+tln+4yvo6YBrwbuBBSUsDJwM/Bp4G7Ah8U9LzBt9FMRWk8ok2+7mke6rbzyWtTCns/t32A7ZvB75CKeCwfaXtk20/YvsO4MuUgnl+nGX757ZnUQrZcbc/oINt32f7T8BlwEm2r7Z9L/BrSoXWbd/q9zkd+CXwtqqltSPwSdv3274W+BKwc9frbrb9dduP2X5orCC2f2f7UtuzbF8CHMUT99eBth+yfTFwMbBBtXw34NO2L3dxse2/A9sC19r+XrXtC4Fjgbc+iX0UU0COBUebbWf7t50HkjYDFgVukdRZvBBwQ7V+ZeCrwEuAZat1d89nhhu67j+z3/YHdFvX/YfGePz0rsd3236g6/F1lFbdSlWO63rWrTpO7jFJehFwEKXFtRiwOHB0z9Nu7br/ILBMdX914Kox3vaZwIs6h/YqiwA/mChPTC1p+cRkcgPwCLCS7eWr2zTbz6/W/xdgYD3b0yiHm9T1+t4h3B8Aluo8qFoUT+15TvdrJtr+grZCdRirYw3gZuBO4FFKQd+97qZxco/1GMqhseOB1W0vRzkvpDGeN5YbgOnjLD+9a/8sXx3qe++A7xtTRCqfmDRs3wKcBHxJ0jRJC1Un7DuHipYF/gHcK2lV4KM9b3Eb5RxJx9+AJaoT74sCn6Z8+5/X7Q/DgZIWk/QSyiGto20/DvwU+H+SlpX0TMo5mH7dum8DVut0aKgsC9xl++GqVfn2J5HrMOCzktZRsb6kpwC/ANaVtLOkRavbpl3niiKAVD4x+byTcojoz5RDascAq1TrDgQ2Au6lnB/5v57Xfh74dHUO6SPVeZb3UQrSmygtoRvpr9/2F7Rbq23cTOnssJftv1brPkDJezVwBqUV890+73Uq8CfgVkl3VsveB3xG0v3AfpQKbVBfrp5/EnAfcDiwpO37KZ0wdqxy3wr8N30q9ZialMnkItpH0tbAD22v1nCUiKFIyyciImqXyiciImqXw24REVG7tHwiIqJ2k+Ui0zTPIiImn3GvG0vLJyIiapfKJyIiapfKJyIiapfKJyIiapfKJyIiapfKJyIiapfKJyIiajdZrvOZy8cOHWsOq+E6ePexpi6JiIh5kZZPRETULpVPRETULpVPRETULpVPRETULpVPRETULpVPRETUbsKu1pKeBmwJPAN4CLgMmGl71pCzRUTEiBq38pG0DfAJYEXgQuB2YAlgO2C6pGOAL9m+r4acERExQvq1fF4H7G77+t4VkhYBtgVeBRw7pGwRETGixq18bH+0z7rHgJ8PI1BERIy+Qc75LA7sAKzZ/XzbnxlerIiIGGWDjO12HHAvcD7wyHDjRETEVDBI5bOa7dcMPUlEREwZg1zn80dJ6w09SURETBmDtHy2AnaVdA3lsJsA215/qMkiImJkDVL5vHboKSIiYkrpd5HptOoC0vtrzBMREVNAv5bPjykXkp4PmHK4rcPA2kPMFRERI6zfRabbVj/Xqi9ORERMBYOc80HSCsA6lLHdALD9+2GFioiI0TbICAe7AfsAqwEXAZsDZwEvH2qyiIgYWYNc57MPsClwne1tgBcC9wwzVEREjLZBKp+HbT8MZZw3238Fnj3cWBERMcoGOedzo6TlKaNYnyzpbuC6YYaKiIjRNmHlY3v76u4Bkk4DlgNOHGqqiIgYaQP1dgOQtCpwTfUwU2hHRMQ86zfCwSeBRbvm7TmL0tFgMeAI4PNDTxcRESOpX4eDtwJf6nr892ow0ecDr5/ojSV9V9Ltki7rWnaApJskXVTdXjfPySMiYtLq29vN9gNdD79aLXscWHKA9/4+MNY8QF+xvWF1+9WgQSMiYnT0q3yWkbRo54Ht78PsabWnTfTG1QgId81vwIiIGD39Kp9jgO9IWqqzQNLSwLerdfPq/ZIuqQ7LrTDekyTtIWmmpJkzZsyYj81FRETb9Kt89gVuB66XdL6k84FrgduqdfPiW8B0YEPgFuY+pzQX2zNsb2J7kz322GMeNxcREW3Ub1Trx4FPSDoQeFa1+ErbD83rxmzf1rkv6VDgF/P6XhERMXn162q9le0zqsrm0jHWTwPWsH3ZE1897nuuYvuW6uH2wMCvbbOPHXpVI9s9ePfpjWw3ImJ+9bvIdAdJB1NGMzgfuIMypcKzgG2AZwL/Md6LJR0FbA2sJOlGYH9ga0kbUiajuxbYc75/g4iImHT6HXb7kKQVgR0o1/ysAjwE/AX4ju0z+r2x7Z3GWHz4fGSNJ6GJ1lhaYhExqL7D69i+Czi0ukVERCwQg0ypEBERsUCl8omIiNql8omIiNpNWPlIWkrSvtV1OUhaR9K2w48WERGjapCWz/eAR4Atqsc3AZ8bWqKIiBh5g1Q+020fDDwKYPtBQENNFRERI22QyuefkpakXBiKpOmUllBERMQ8GWQa7f0poxysLulHwJbArsMMFRERo23Cysf2yZIuADanHG7bx/adQ08WEREja5DebtsDj9n+pe1fAI9J2m7oySIiYmQNcs5nf9v3dh7YvodyKC4iImKeDFL5jPWcQc4VRUREjGmQymempC9Lml7dvkyZYiEiImKeDFL5fAD4J/CT6vYIsPcwQ0VExGgbpLfbA8AnasgSERFTxISVj6R1gY8Aa3Y/3/bLhxcrIiJG2SAdB44Gvg0cBjw+3DgRETEVDFL5PGb7W0NPEhERU8YgHQ5OkPQ+SatIWrFzG3qyiIgYWYO0fHapfn60a5mBtRd8nIiImAoG6e22Vh1BIiJi6hhopAJJLwCeByzRWWb7yGGFioiI0TZIV+v9ga0plc+vgNcCZwCpfCIiYp4M0uHgLcArgFttvwvYAFhuqKkiImKkDVL5PGR7FmUqhWnA7cDqw40VERGjbJBzPjMlLQ8cShlQ9B/AWcMMFRERo22Q3m7vq+5+W9KJwDTblww3VkREjLJBZjI9pXPf9rW2L+leFhER8WSN2/KRtASwFLCSpBUAVaumAavWkC0iIkZUv8NuewL/DjyDcq6nU/ncBxwy3FgRETHKxj3sZvurwLOAz9le2/Za1W0D2xNWPpK+K+l2SZd1LVtR0smSrqh+rrBgfo2IiJhM+p7zsf048OZ5fO/vA6/pWfYJ4BTb6wCnkEnqIiKmpEGu8zlF0g6SNPFT57D9e+CunsVvAo6o7h8BbPdk3jMiIkbDIJXPnpQJ5f4p6T5J90u6bx63t7LtW6r7twIrj/dESXtImilp5owZM+ZxcxER0UaDXOez7DA2bNuS3Gf9DKBT64z7vIiImHwGHdX6jcBLq4e/s/2LedzebZJWsX2LpFUoQ/VERMQUM8hFpgcB+wB/rm77SPr8PG7veOZMTrcLcNw8vk9ERExig7R8XgdsWA0uiqQjgAuBT/Z7kaSjKFMxrCTpRmB/4CDgp5LeA1wHvG3eo0dExGQ10GE3YHnm9FwbaDoF2zuNs+oVA24zIiJG1CCVz+eBCyWdRhnl4KXk+pyYBx879Krat3nw7tNr32ZETGyQ3m5HSfodsCml19nHbd867GARETG6Bj3stgWwFaXyWQT42dASRUTEyBukt9s3gb2AS4HLgD0lfWPYwSIiYnQN0vJ5OfBc24bZvd3+NNRUEREx0gYZXudKYI2ux6tXyyIiIubJIC2fZYG/SDq3erwpMFPS8QC23ziscBERMZoGqXz2G3qKiIiYUgbpan06gKRp3c+33TtdQkRExEAmrHwk7QF8BngYmEW50NTA2sONFhERo2qQw24fBV5g+85hh4mIiKlhkN5uVwEPDjtIRERMHYO0fD4J/FHSOcAjnYW2Pzi0VBERMdIGqXy+A5xKGeFg1nDjRETEVDBI5bOo7Q8PPUlEREwZg5zz+bWkPSStImnFzm3oySIiYmQN0vLpTArXPXNpulpHRMQ8G+Qi07XqCBIREVPHuJWPpDf3e6Ht/1vwcSLq08TMqpDZVSOgf8vnDX3WGUjlExER82Tcysf2u+oMEhERU8cgvd0iIiIWqFQ+ERFRu1Q+ERFRuwkrH0lLSdpX0qHV43UkbTv8aBERMaoGucj0e8D5wBbV45uAo4FfDCtUxFTVRPfvdP2OJgxy2G267YOBRwFsP0iZUC4iImKeDFL5/FPSkpRre5A0na6pFSIiIp6sQQ67HQCcCKwu6UfAlsCuQ8wUEREjbpCx3U6SdD6wOeVw2z6ZUjti6sh5qBiGCSsfSScAPwaOt/3A8CNFRMSoG+SczxeBlwB/lnSMpLdIWmJ+NirpWkmXSrpI0sz5ea+IiJh8BjnsdjpwuqSFgZcDuwPfBabN57a3yeG7iIipaZAOB1S93d4A/CuwEXDEMENFRMRoG+Scz0+BzSg93g4BTrc9az63a+AkSQa+Y3vGfL5fRERMIoOc8zmccqHpXrZPWwAVD8BWtjcCXgvsLemlvU+QtIekmZJmzpiRuikiYpT0m8n05bZPBZYG3iTNPajB/Mxkavum6uftkn5GaVn9vuc5M4BOreN53VZERLRPv8NuLwNOZewZTed5JlNJSwML2b6/uv8vwGfm5b0iImJy6jeT6f7V3c/YvqZ7naS15mObKwM/q1pSiwA/tn3ifLxfRERMMoP0djuW0sOt2zHAxvOyQdtXAxvMy2sjImI09Dvn8xzg+cBykt7ctWoaMF8XmUZExNTWr+XzbGBbYHnmPu9zP+VC04iIiHnS75zPccBxkrawfVaNmSIi+spgp5PfIOd8LpS0N+UQ3OzDbbbfPbRUEREx0gapfH4A/BV4NaVL9DuAvwwzVETEZNJESwz6t8ba3jocZISDZ9neF3jA9hHA64EXzWO2iIiIgSqfR6uf90h6AbAc8LThRYqIiFE3yGG3GZJWAPYFjgeWAfYbaqqIiBhpg8znc1h193Rg7eHGiYiIqaDfRaYf7vdC219e8HEiImIq6NfyWba2FBERMaX0u8j0wDqDRETE1DFhbzdJ60o6RdJl1eP1JX16+NEiImJUDdLV+lDgk1Rdrm1fAuw4zFARETHaBql8lrJ9bs+yx4YRJiIipoZBKp87JU2nmspa0luAW4aaKiIiRtogF5nuDcwAniPpJuAayvhuERER82SQi0yvBl4paWlKS+lByjmf64acLSIiRtS4h90kTZP0SUmHSHoVpdLZBbgSeFtdASMiYvT0a/n8ALgbOIsyc+l/AgK2t33R8KNFRMSo6lf5rG17PQBJh1E6Gaxh++FakkVExMjq19utM5UCth8HbkzFExERC0K/ls8Gku6r7gtYsnoswLanDT1dRESMpH5juy1cZ5CIiJg6BrnINCIiYoFK5RMREbVL5RMREbVL5RMREbVL5RMREbVL5RMREbVL5RMREbVL5RMREbVrpPKR9BpJl0u6UtInmsgQERHNqb3ykbQw8A3gtcDzgJ0kPa/uHBER0ZwmWj6bAVfavtr2P4H/Bd7UQI6IiGiK7VpvwFuAw7oe7wwcMsbz9gBmVrc9FtC2F8j7LOD9kUyTLE8yTd5MbcszlTO1tsOB7Rm2N6luMxbQ2+6xgN5nQUqmibUtDyTToNqWqW15YIpmaqLyuQlYvevxatWyiIiYIpqofM4D1pG0lqTFgB2B4xvIERERDek3mdxQ2H5M0vuB3wALA9+1/aeaNr+gDt8tSMk0sbblgWQaVNsytS0PTNFMqk4uRURE1Ka1HQ4iImJ0pfKJiIjapfKJiIjapfKJiIja1d7brSmSlgYetv1401kAJK0APAN4CLjW9qyG82wCvKQr02XAybbvbjDT04AtezLNbMG+atVnKSbWtv+3NpK0ELABXf9vtm8f2vZGtbdbtSN3BN4BbAo8AiwO3An8EviO7StrzrQcsDewE7AYcAewBLAycDbwTdun1ZzpXcAHgGuA84Hbq0zrUgr+y4B9bV9fY6ZtgE8AKwIX9mSaDhwDfMn2fTXlad1nqcq1BfBvlC8NqzCngv4l8EPb907lTG38f6tytWYfVXmmAx8HXglcwZz9tC7wIPAd4IgFXWGPcuVzOvBb4DhKDT6rWr4isA3wduBntn9YY6aTgSOBE2zf07NuY8o4d5faPrzGTHtTrrV6aJz1GwJPsX1KjZm+AHx9rApP0iLAtsDCto+tKU8bP0u/Bm6uMs1k7gp6G+ANwJdt13YBd9sytfT/rVX7qMp0FPAt4A/uqRCqow9vB+62fcQC3e4IVz6L2n50fp8T0cbPkqSVbN85v88Z9Uxtk300x8h2OLD9qKQXS9qo33PqzDQWSf/V8Pa3r77BI+mpko6UdKmkn0haraFMa0s6VNLXJK3RRIZu1WdpoerwG5IWk7RRZ791nlNzpicUTt15xnvOMNm+U9IzJK3U7zl15ZG0qKS3S3pzNY9Y49q2j8Yj6cihb2OEWz7fAZ5PadJeBezsMn9Qk5m+1ruI0vQ/EsD2BxvI9Gfbz6vu/4RyLPxoyvHfd9h+VQOZzgUOo5xX2QfYxfaZdefoyrMd5bj3LGAv4FPAP4BnA++1fUIDmbak7KNZwLuBzwFrU85tvM32WQ1k2g/YlTJs1lG2G52lWNLPKOdTFqec53lDkx1oqkyt2kcAknoP8YlyCPBUANtvHMqGhz1nQ1M34M9d9z8LXAJ8HdgQ+FhDmW4Afgi8E9ilut3Rud9Qpsu77p/fs+6ihjJd0nV/Q0pHiHuANwNnNJDnQuDpwFrAfcCzq+XPpPS+a2IfnQusB2xB6fiwVbV8I+DMhjL9FViU8oXvCMr4jf8BrAP8WwN5Lu26/x7gOuAESkea/8k+mp3pgqpc2hp4WfXzlur+y4a13ZE97AY8WnWJxfa+lN4lZ1MKsb80lOl5lILiNZRuzEcA99s+wgv4ZN6T8DtJn5G0ZHV/e5jd46z23lKV2yStD2D7Itsb217e9v/Z3qqJQLZvtX0NcL3ty6tl19HcoetFbV/q0sK5w/YZVaYLgCUbyvRYieCHbe8CHEIpZBcDlm4gzyOdw1sunQo2Bg4C/gb8oIE80L59BLAJ5QvefwL32v4d8JDt022fPqyNjvJht+2AOzv/lG1S9bT5IqVr5fttr9lglkUpH7p3V4tWAx6gfEP8hGvsYt2V6anAIrZvqXvbY5F0IbCx7VmSNrN9brV8YeBi2y9oINPFtjeo7m9n++dd6y5rKNOewBW2T61722OpDk0+VFXIrdC2fdStOsf7FeA24I22h3q+dWQrn7FI2qgtH0RJAt4HbGH735rOA7Ovi1jE9t+bztJL0gG2D2ho25tSDuE83LN8Tcrhrtq6WHdt+43Ab20/2LN8OrCD7YPrzjQWSU+3fWvTOTokbWv7F03n6NbCffR6YEvbnxrqdqZY5XOB7XF7vzWhpf8MjRX042nb365NX2Q62laIQSv/bq3KA63NtIftoc7pM8rnfMaipgOM4TNNBxjDcHq3zJ+2/e0OazrAGH7VdIAxtO3v1rY80M5Mew17A1Ot8jmw6QBjaOMHr42ZNm46QI827qM2Zjq06QA99mw6wBjato+ghs/SlDrs1iHpObb/2nQOgO4T2G0haSG3dOBFSfvZbry12HuSvw0kvc/2N5vOMRlIepXtk5vO0VaSVrN94zC3MdVaPh0nNR2go6vnVO0Xc47Hc8Yu26/pLGPYrekAAJ2KR9JzGo4yW9MVj6T1JJ0t6QZJM1RGku6sa9UXLKC28dy6TZZ91Kl4VAYeHoqRbfmMMZrA7FWUCzqn1ZlnIpKuH3bXxierqUySxhutWsCStlszFUiD+2g9yuGaVYFfAx93dfW+pHNtb9ZApjMoIy2cTfmS8C5Kl92rJF1o+4U15xlvcE4BL7dd+3U1bdtHExnm57s1/8RD8C7KlcOPjLFup5qzABP+MzylziyzNzxBQV9nli73AJvavq13haQb6g4zwReZ5WuM0u1bwAHMKcTOkPRG21dRrqBvwrK2T6zuf1HS+cCJknYGmviW+xLKxeX/6FkuoPbKudK2fYSkS8ZbRRmWaChGufI5jzL8/R97V0g6oP44QDv/Ge6hRQV95UjK0DVPyAT8uOYs0MIvMrSwEINyrZir+WhsnyZpB+BYytxMdTsbeHCsq/QlXd5Ans6227SPoFQwrwZ6x70T8ITyc0EZ5crnLcDDY62wvVbNWTra+M/QtoIe25/us+7jdWaptPGLTBsLsf8Gnkv5nFPlukTSK4B96w5j+7V91r20zixdWrWPKr8AlrF9Ue8KSb8b1kZH9pxPjIbqhOw6lPGvALD9+5ozrEiZNvvBCZ9cE0lvB662fXbP8jUoM8/u3kyydpL0dMrRBQPnte1i3Klo5CsfSesAn6cM6tldgK3dWKiWakNB35NnN8qUCqsBFwGbA2fZfnlTmWJi1dh8H+eJ/3ON/N2qz9F+lCkCRBmt+TO2v9tEnipTq/ZRh8r8Z1tRKukzhzmKx1Toav09ysnZxyhzVBxJGT68MZI2l3SepH9I+qekx/uc+K8r027A7ylDvB9Y/TygyUyUimdT4Drb2wAvpJyjaoSkdSQdI+nPkq7u3JrKU2V6qqQvSvqVpFM7tyYzAT+ijBy/FuWzdC3l0GVTPgq80Pau1UjSG1MK/ia1bR91Lq04gtL5aSXge5LGPQQ+v6ZC5bOk7VMorbzrqjHLXt9wpkMoJ6qvoPQo2w34RqOJWlbQVx7uDOYpafHqwuBnN5indV9kaGEhBjylmsLg0WpY/ncDTX6j/ztwf9fj+6tlTWrbPgJ4B6Xz0f6296ccadh5WBsb5Q4HHY+oTH98haT3AzcByzScCdtXSlrY9uOUbxgXAp9sMNLDth+WNLugl9RkQQ9wo6TlgZ8DJ0u6mzIhWFOWtH2KJLnM5XNA1cusyYtxn2L7cEn7VB1ZTpfUdOXTmVL8lmqE5JtpoBOEpA9Xd68EzpF0HOVw0psok0s2qRX7qMfNlEOAnY5ai1PKy6GYCpXPPsBSwAcpM5puQ5k5tEkPSloMuEjSwZRZA5tuhbatoMf29tXdAySdBiwHnNjnJcPWxi8ybSzEPqcyPcd/UGYPngZ8qIEcy1Y/r6puHcc1kKVXW/YRkr5OqZTvBf4k6eTq8asoM+YOZ7uj3uGgjSR1ujYvRvnALQd80/aVjQarSHoZVUFv+58NbH8Z273XQj3p5yxoKvP6/IVyYelnKQXGF3p7nNWcaVvgD8DqzCnEDrQ93gXNEXOR1PfLuIc0y/LIVj6SDgW+ZvvSMdYtDfwr8IjtH9UerkXaWNBLOoXSu+044HzbD1TL16a0XN8GHGr7mLoyxcSqk9PftH3XOOtfDixV1/xVVRnwVduXjbGukTKgbfuoSaN82O0bwL7VGFiXAXdQjmeuQ/l2+F3KydraSDoBmEFpUTzas25tYFfg2pq7gB4n6SImKOiB2gp626+Q9DrK8PdbVtfZPApcTpl6fJc6r9No4xeZlhZilwInSHoYuIC5/+c2BH4L/FeNeb4B7NemMoD27aPGyqWRbfl0SFoG2ARYBXgI+IvtRkYTqC50+zCwA3AXcz54a1FOih5iu/bj0VVB/w5gS2AFSm+uTkF/+FS/IE/ShsCngH6F2LdtjzX8zrAyvQn4GOXk8LiFmO076srUlW0dymdp9v8c8HvbD9WdpcrTmjKgK1Nr9lFT5dLIVz5tJWlN5nzw/tamq+fbRNKqlOF/ZrfSm7rwNYVYjLo6y6WRrXwkXcrYAywKsO31a440J4C0FnBL1zUsSwBPt31tg5m2B07tjBVW9Xzb2g1OmCbpvymHtP4MPF4ttu02TvMdlaq31Ftt31M9XgH4X9uvrjlHm8uAVuyjnky1lkujXPk8s9/66jqNRkiaCby405Os6nZ9pu1NG8x0ke0Ne5Zd6AbnF1EZbHX9Og9njZMjhdiTy/SEz00Tn6WWlwGt2Ec926+1XBrZDgdNfrAGsEh3F2bb/6z+0E0a6zqjpj8fV1Pmpmm08gG2bXj7/azUqXgAbN8t6WkN5gGYJWkN29fD7Eqg9m+5LS8DWrGPetRaLjVduAydpM0p1z88l3JdzcLAA252JtM7VCb+Or7K+CbgzgbzAMyU9GXmDPOzN3B+g3kAHqRciHsKXRWQ7Q/WGSKF2JP2n5TJ7U6ntA5fAuzRVJiWlgFj7aM9G8wDNZdLI3vYraNqSu4IHE05WfxOYF3bjQ1lI2k6pYvnMygfvBuAnV1moWwq09KU+UReWS06Gfhcp+t1Q5nGvPhtWBe9TaSNhZik11C6yc5V0Nv+TVOZqlwrUcYGAzjbdmNfrtpYBlS55tpHwL29XZ1rzlNruTQlKh/bm0i6pHNsvuljq13ZlgGw/Q9Jm9puekyu6GOyFGJNFfSSFqaMf/eP6vHmlEoa4ELb94/74uHmanMZIMqAom8HtrU9tGmrB1VXuTTyh92YM47axWrPOGodawA7SdqRMq7SJk0FURk77QnfRNzg/CJq4VxMbsmAsN0Fve07Jd1JKeifVxWsTRT0/w3cDhxcPf4x5bqoJSnXIjU1jUHryoCqYn47sB1lLL69gY80malLLeXSVKh8dqZ80PamjKO2GuViqkZU/eh3qm6PUq5h2aTJbtaV7g/+EpR99FhDWTq+B+wPfIUy2sK7aLbQaFMh1saC/hWUaTk67rX9xurb/R8ayNPRmjJA0n8BbwWuB46iTIMxs6lDyV251qTmcmlkK5/qZNlqtr9RPT4deBrl2/1ZlCt36850FuWK+P8FdrB9haRrWlDxYLu3c8GZkoY2ou2A2jaFQWsKMdpZ0C9ku/sLy8eh9EXvHMqpUxvLAMrcXX+jzAt1gu1HJDV67qOpcmlkKx/K0CM7dj1enDKD4TKUb9RNDEp5G7AqsDLwVMpkcq046aYyflrHQpR9tVxDcTpaMYVBSwuxVhX0lcUkLds55Gf7JACVqQOW6PvK4WhjGbAKZaqCnYD/qQ53LylpkZ6/Z50aKZfacu5jGBazfUPX4zNs31V1SV26iUC2t6OMD3Y+5Vv8NcAKkjZrIk+P87tuZ1HmGXlPo4nmnotpY0rLo4m5mD4GdE9R0CnEtgbe20AeqAr6zoMWFPRQBqD9iaQ1Oguqrt9HAYc1kKeNZcDjtk90mc57OmX+rDOBmyT9uKFM29FAuTSyvd0kXWn7WeOsu8r29LozjZHjaZThY3YE1rC9egMZZl8jEmOTdF73Vd6SDrH9/ur+2bY3H//VQ8v0YUq3+L16rvH5FmWYpC/WnanKsBdlENalKd117wcOsv2tBrK0vgzoqL5IbG/7yBZkqaVcGuXK50fA72wf2rN8T8qYZTs1k2xskp7ZxMWMki6wvVF1/1jbjXXG6MrUdyI01zy2W1sLsTYV9L06rbKmuldXGVpfBkjaCtgMuNT2yU3n6TXMcmmUK5+nUZq0j1B6/0A5VLI4sJ3t2xrI9D3GP5Zq27Uf5uq+3qFF1z7cQbnA7SjgHErBOpvt02vO0+pCrA0F/Vi6CtbLOocFa95+G8uAc21vVt3fndJ55WfAv1A6IBzUQKZGyqWRrXw6VCbVen718E+2T20wy1ititUpPacWtr1azZF6Wz6z7zepuoalc1J2fcq8QkfZ/lNDeVpXiPVquqCvMrSuYK2ytKkM6P6ydx7wOtt3qIwwcrbt9RrI1Ei5NPKVT1upzBD4KeCllOtYDnfXoH415ngceIDSuliSMp4a1WO72fGvkLQ4pRL6AnCg7UMazNKmQqx1BX0bC9a2kXQxpaPKQsBvbG/Sta7xIw91lkuj3NW6lSQ9B/g08EJKgbpXg10ssb1wU9vup6p0Xk+peNYEvkYpXBtTVTaNVTg9Fu26vwfwqqqg/yJlnLAmWhkLqUzpsBDli+0dALYfkNT0BcttsRylV5kAS1rF9i1V93j1f+nwNFEupfKpkaSjKYdrvkRp0j4OTCvXBYLtu5pL1x6SjgReAPyK0tq5rOFIbdTGgr6VBWub2F5znFWzgO1rjDJbU+VSDrvVSNK1zDmx1/nZ+ae0GxyzrE0kzaIcCoS5T4S24lBgG1SfpVlU+wTYsqugP8M9EwM2SdJSwMq2r2k6S1t0XwvVrYnLHpoql1L5RIyQNhT0bSpY20pzZscV5aLgtYDLbT+/7wtHSA67NUDS9pQLAe+tHi9P6bL78yZzxeQzTkH/eO1B5vZLxihYmdNZY8rr7XwhaSPgfQ3F6WSotVxKy6cBki7qPSzShp4uMflMhm/QnYLV9m5NZ2kzSZc22SOw7nIpLZ9mjDWmXv4W8aS18Rt0L9sXSHpR0znapBoeqWMhYCPg5obidOfoNbRyKQVeM2ZK+jLwjerx3pReQhHzpQ0FfUsL1rZZtuv+Y5RDlcc2lKWj1nIph90aUF10ty9lYEiAk4HP2X5g/FdFPNE4Bf1TbL+6oUhI2r/r4WPAtcCxth9uJlF7SVrK9oMTP3P46i6XUvlETGJtLujbVLC2jaQtgMOBZWyvIWkDYE/brTpkOkypfGok6QT6TNJU92jNMTraVNCnYJ2YpHOAtwDHdw1JdJntFzSQpZFyKed86jXWHCu9F3VFDKy7oAfaUtD/D/Bqqgn4bF8s6aUN5mkl2zd0RhGoNNVFvpFyKZVPvZZn7umYz6VMW2uqaZAjnqT/oYUFfYsK1ra6QdKLKcMQLUqZtfcvDWVZngbKpVGeRruNeqdjXgzYhDLK7V5NBIrJz3NPFQ3NF/RzFaySPkJzBWtb7UXpTbYqcBOwYfW4CY2US2n51GusOeX/Dvy96mkS8WS16Rt0x17AV5lTsJ5EcwVrK9m+E3hH0zkqjZRL6XBQI7V0OuaYvCStRCnoX0k5Pn8SsE9VeETLSNqvz2rb/mxtYSpNlUtp+dTrHEm7e+zpmM9tKFNMYm36Bt3GgrWFxrpmZmngPcBTgCb2USPlUlo+NZoM0zHH5NDGgl7Sf4yxeHbBanuZmiO1mqRlKYdJ3wP8FPiS7dsbyNFIuZTKpwFtmo45Jqe2F/RtKVjbSNKKwIcpLdYjgK/avrvZVPWXS6l8Iia5NhX0bS1Y20LSF4A3AzOAb9j+R8ORGpPKJ2KSaltBn4J1YtUsvY9QhkKa0rP0pvKJmITaWNCnYI0nI5VPxCSUgj4mu1Q+ERFRuwyvExERtUvlExERtUvlE5OapFpPtEtaU9Lb5/M9/l3SUmMs31/S53uWbShp4LHaJL1R0icmeM4B1WCfvcvXlHTZoNuKmB+pfCIGJGkRYE1gviof4N+BJ1Q+wFHAv/Ys27FaPiFJi9g+3vZB8xcvYvhS+cRIkLS1pNMlHSfpakkHSXqHpHMlXSppevW870v6tqSZkv4madtq+RKSvlc990JJ21TLd5V0vKRTgVOAg4CXSLpI0oeq1sIfJF1Q3V7cled3ko6R9FdJP1LxQeAZwGmSTuv+HWz/Dbhb0ou6Fr8NOErS7pLOk3SxpGM7Laeu3+cc4OAq7yHVujdIOqf6fX4raeWu991A0lmSrpC0+xj7c2FJX6i2eUk1zheSVpH0++r3v0zSS+b/rxdTUQYWjVGyAfBc4C7gauAw25tJ2gf4AKXFAaX1shkwnVIJPIsy5L9tryfpOcBJktatnr8RsL7tuyRtDXzEdqfSWgp4le2HJa1DaaVsUr3uhZThSm4GzgS2tP01SR8GtqkGBe11FKW1c46kzYG7bF8h6a7OwI+SPkcZzeDr1WtWA15s+3FJu3a91xnA5rYtaTfKvC2dYXnWBzanDMlzoaRf9uR4D3Cv7U0lLQ6cKekkyrVFv7H9/yQtzNgtuIgJpfKJUXKe7VugDAVPmV4A4FJgm67n/dT2LOAKSVcDzwG2oirMbf9V0nVAp/I52fZd42xzUeAQSRtSJnFbt2vdubZvrPJcRKn0zpjgd/gJ8Mdq7LbuQ24vqCqd5SlTZv+m6zVH2x5rArnVgJ9IWoUyQdg1XeuOs/0Q8FDVAtsMuKhr/b8A60t6S/V4OWAd4DzguypzB/3cdvdrIgaWw24xSh7puj+r6/Es5v6i1Xtx20QXu401DH7Hh4DbKK2uTSiF/Fh5HmeAL3vVpF7XAC8DdqBURgDfB95vez3gQGCJAfJ9HTikes2ePa+ZaB8I+IDtDavbWrZPsv174KWUSeK+L+mdE/1OEWNJ5RNT0VslLVSdB1obuBz4A9W8ONXhtjWq5b3uB5bterwccEvVktoZWHiA7fe+R6+jgK8AV3daTtXzb6laHIPO37McpZIA2KVn3Zuq81xPoUyXfF7P+t8A7622h6R1JS0t6ZnAbdUhwMMohyQjnrRUPjEVXU+ZJOvXwF62Hwa+CSwk6VJKa2NX24+M8dpLgMerE/8fql63i6SLKYfv+rWSOmYAJ/Z2OOhyNOVcUXcvt32Bcyjnjv46wDYADgCOlnQ+0Ht+6RLgNOBs4LO2b+5ZfxjwZ+CCqvv1dygtt62BiyVdSOmZ99UBs0TMJcPrxJQi6fvAL2wf03SWiKksLZ+IiKhdWj4REVG7tHwiIqJ2qXwiIqJ2qXwiIqJ2qXwiIqJ2qXwiIqJ2/x/08kbq8NwmAwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moved-greene",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[Neu5Ac(a2-?)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.9778383374214172),\n",
       " ('Gal(b1-3)GlcNAc(b1-3)[Gal(b1-4)GlcNAc(b1-6)]Gal(b1-4)Glc-ol',\n",
       "  0.7708687782287598),\n",
       " ('Neu5Gc(a2-3)Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)Glc1Cer', 0.44020554423332214),\n",
       " ('Gal(b1-4)Glc-ol', 0.6584441065788269),\n",
       " ('GlcNAc6S(b1-3)Gal(b1-4)Glc-ol', 0.8197453022003174),\n",
       " ('Neu5Ac(a2-3)Gal(b1-3)GalNAc', 0.7841342091560364),\n",
       " ('Gal(b1-4)Glc-ol', 0.6584441065788269),\n",
       " ('Glc1Cer', 0.8197453022003174),\n",
       " ('GalNAc(b1-4)Gal(b1-4)Glc1Cer', 0.8446291089057922),\n",
       " ('Fuc(a1-2)[Gal(a1-3)]Gal(b1-?)GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-3)GalNAc',\n",
       "  0.6722375750541687)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean-personality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-arnold",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-passion",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "likely-grove",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-command",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collective-cooler",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesbian-closer",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-butter",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 8], labels=[5], string_labels=[5], num_nodes=5, y=1),\n",
       " Data(edge_index=[2, 8], labels=[5], string_labels=[5], num_nodes=5, y=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_graphs([\"Neu5Ac(a2-3)Gal(b1-4)Glc\",\n",
    "                  \"Fuc(a1-2)Gal(b1-3)GalNAc\"], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-tours",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-glass",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 16], labels=[10], string_labels=[2], num_nodes=10, y=[2], batch=[10], ptr=[3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_to_dataloader([\"Neu5Ac(a2-3)Gal(b1-4)Glc\",\n",
    "                                 \"Fuc(a1-2)Gal(b1-3)GalNAc\"], [1, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heated-georgia",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-female",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch_geometric.loader.dataloader.DataLoader>,\n",
       " 'val': <torch_geometric.loader.dataloader.DataLoader>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_to_train([\"Neu5Ac(a2-3)Gal(b1-4)Glc\", \"Fuc(a1-2)Gal(b1-3)GalNAc\"],\n",
    "                    [\"Neu5Ac(a2-6)Gal(b1-4)Glc\", \"Fuc(a1-2)Gal(a1-3)GalNAc\"],\n",
    "                    [1, 0], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continued-tokyo",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collective-strike",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (dict): dictionary of form glycoletter:index\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "therapeutic-alias",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cognitive-diploma",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "checked-effect",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rha(a1-2)Rha(a1-4)Glc', 'Glc(b1-4)GlcA(b1-4)Glc(b1-4)Glc', 'Man(a1-2)Man1P(a1-6)Man(a1-6)[Man(a1-3)]Man(a1-6)[Man(a1-3)]Man(b1-4)GlcNAc', 'Glc(b1-3)6dTalOMe(a1-3)Glc', 'Glc(?1-?)[Glc(?1-?)]Gal(b1-4)Gal(b1-3)Gal(b1-4)Glc(b1-6)Glc', 'GlcA(b1-4)GlcA(b1-4)Glc(b1-4)[Gal4Pyr6Pyr(b1-6)Gal(b1-6)Glc(b1-6)Gal(a1-4)GlcA(b1-4)Glc(b1-4)Glc(b1-6)]Glc', 'Xyl(b1-2)Glc6Ac', 'GalNAc(b1-3)Gal(a1-4)Gal(b1-4)Glc(b1-4)Glc(b1-4)LDManHep(a1-5)KdoOPPEtN', 'Rib5P-ol(5-6)Gal(a1-3)FucNAm(a1-3)GlcNAc(b1-3)Rib5P-ol', '[Gal(a1-6)]Man(b1-4)Man(b1-4)Man(b1-4)Man(b1-4)Man']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ordinary-balance",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(b1-4)GlcNAc', 'GalA(a1-3)Glc(a1-5)Kdo', '[Man(a1-2)Man(a1-2)Man(a1-2)]Man(a1-6)Man', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAcOS(b1-2)Man(a1-3)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'HexNAc(?1-?)[Fuc(a1-?)]GlcNAc(b1-2)Man(a1-3)[Fuc(a1-?)[HexNAc(?1-?)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'ManNAc(a1-3)Gal(b1-4)LDManHep(a1-5)KdoOP', 'GalNAc(a1-3)[GlcNAc(a1-4)]GalNAc(a1-4)Glc(a1-4)Gal(b1-3)GalNAc', 'Gal(b1-?)GlcNAc(b1-6)[GlcNAc(b1-3)]GalNAc', 'Glc(b1-4)Glc(b1-4)Glc(b1-3)Gal']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.target.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flush-joyce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-bailey",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gal(b1-4)GlcNAc-ol\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "glycans, labels = prepare_multilabel(df_species[df_species.Order == 'Carnivora'])\n",
    "print(glycans[50])\n",
    "print(labels[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
