{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indie-confirmation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-brighton",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generic-taxation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bored-quality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.8913352272727273\n"
     ]
    }
   ],
   "source": [
    "mammal = [1 if k == 'Mammalia' else 0 for k in df_species[df_species.Phylum=='Chordata'].Class.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Phylum=='Chordata'].target.values.tolist(), mammal)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['exhaustive'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "federal-lover",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moved-greene",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neu5Ac(a2-8)Neu5Ac(a2-3)[Gal(b1-3)GalNAc(b1-4)]Gal(b1-4)Glc1Cer',\n",
       "  0.49235206842422485),\n",
       " ('Gal(?1-?)[Neu5Gc(a2-?)]Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-3)[Gal(?1-?)[Neu5Gc(a2-?)]Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.5232053399085999),\n",
       " ('Gal3S(b1-3)[Fuc(a1-2)]Gal(b1-3)[GlcNAc(b1-6)]GalNAc', 0.5275742411613464),\n",
       " ('Gal1Cer3S', 0.7475326061248779),\n",
       " ('Man(a1-2)Man(a1-6)[Man(a1-3)]Man(a1-6)[Glc(a1-3)Man(a1-2)Man(a1-2)Man(a1-3)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.8494867086410522),\n",
       " ('GlcNAc(a1-4)Gal(b1-4)[Neu5Gc(a2-3)]Gal', 0.584469199180603),\n",
       " ('Neu5Ac(a2-8)Neu5Ac(a2-3)[Gal(b1-3)GalNAc(b1-4)]Gal(b1-4)Glc1Cer',\n",
       "  0.49235206842422485),\n",
       " ('GalNAc(b1-4)GlcNAc(b1-2)Man(a1-3)[Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8354285359382629),\n",
       " ('Neu5Ac(a2-3)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-?)[Gal(b1-4)GlcNAc(b1-2)Man(a1-?)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.8073118329048157),\n",
       " ('Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-?)[Gal(b1-4)GlcNAc(b1-?)]Man(a1-3)[Man(a1-?)Man(a1-6)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8784158825874329)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean-personality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-arnold",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-passion",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "likely-grove",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-command",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collective-cooler",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesbian-closer",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-tours",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heated-georgia",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continued-tokyo",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collective-strike",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "therapeutic-alias",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cognitive-diploma",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "checked-effect",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-4)[GalOS(b1-4)GlcNAc(b1-2)]Man(a1-3)[Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Rha(a1-2)[Rha(a1-4)]Glc', 'GlcNAc(?1-?)Gal(?1-?)[GlcNAc(?1-?)]GalNAc', 'Neu5Ac(a2-?)Gal(b1-3)[Gal(b1-?)GlcNAc(b1-6)]GalNAc', 'Gal(b1-4)Gal(b1-4)Gal', 'Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Man(a1-?)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'QuiN(b1-3)Rha(a1-3)GlcN(a1-3)[Glc(b1-2)Glc(a1-4)]GalN(a1-3)LDManHepOP(a1-3)LDManHepOP(a1-5)[Kdo(a2-4)]Kdo(a2-6)GlcN(b1-6)GlcN1P', 'GlcN(b1-2)DDManHep(a1-3)DDManHep(a1-3)DDManHep(a1-3)DDManHep(a1-3)Glc(a1-6)Glc(a1-6)Glc(a1-6)DDManHep(a1-3)Fuc(a1-3)GlcN(b1-2)[Glc(a1-4)Gal(b1-7)]DDManHep(a1-2)LDManHep(a1-3)LDManHep7P(a1-5)Kdo(a2-6)GlcN(b1-6)GlcN', 'GlcNAcA(b1-4)ManNAcANOOrn(b1-4)GlcNAc(b1-3)D-FucNAsp(a1-4)GlcNAcA', 'L-GulA(a1-4)ManA(b1-4)Man(b1-4)L-GulA(a1-4)L-GulA(a1-4)ManA']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ordinary-balance",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(b1-4)GlcNAc', 'GalA(a1-3)Glc(a1-5)Kdo', '[Man(a1-2)Man(a1-2)Man(a1-2)]Man(a1-6)Man', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAcOS(b1-2)Man(a1-3)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'HexNAc(?1-?)[Fuc(a1-?)]GlcNAc(b1-2)Man(a1-3)[Fuc(a1-?)[HexNAc(?1-?)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'ManNAc(a1-3)Gal(b1-4)LDManHep(a1-5)KdoOP', 'GalNAc(a1-3)[GlcNAc(a1-4)]GalNAc(a1-4)Glc(a1-4)Gal(b1-3)GalNAc', 'Gal(b1-?)GlcNAc(b1-6)[GlcNAc(b1-3)]GalNAc', 'Glc(b1-4)Glc(b1-4)Glc(b1-3)Gal']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.target.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flush-joyce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
