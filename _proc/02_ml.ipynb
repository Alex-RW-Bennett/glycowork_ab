{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indie-confirmation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience=7, verbose=False)\n",
       "\n",
       "Early stops the training if validation loss doesn't improve after a given patience."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southeast-brighton",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model, dataloaders, criterion, optimizer, scheduler,\n",
       ">                   num_epochs=25, patience=50, mode='classification',\n",
       ">                   mode2='multi')\n",
       "\n",
       "trains a deep learning model on predicting glycan properties\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| dataloaders (PyTorch object): dictionary of dataloader objects with keys 'train' and 'val'\n",
       "| criterion (PyTorch object): PyTorch loss function\n",
       "| optimizer (PyTorch object): PyTorch optimizer\n",
       "| scheduler (PyTorch object): PyTorch learning rate decay\n",
       "| num_epochs (int): number of epochs for training; default:25\n",
       "| patience (int): number of epochs without improvement until early stop; default:50\n",
       "| mode (string): 'classification', 'multilabel', or 'regression'; default:classification\n",
       "| mode2 (string): further specifying classification into 'multi' or 'binary' classification;default:multi\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns the best model seen during training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generic-taxation",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model, lr, lr_patience=4, factor=0.2,\n",
       ">                      weight_decay=0.0001, mode='multiclass', gsam_alpha=0.0)\n",
       "\n",
       "prepares optimizer, learning rate scheduler, and loss criterion for model training\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (PyTorch object): graph neural network (such as SweetNet) for analyzing glycans\n",
       "| lr (float): learning rate\n",
       "| lr_patience (int): number of epochs without validation loss improvement before reducing the learning rate;default:4\n",
       "| factor (float): factor by which learning rate is multiplied upon reduction\n",
       "| weight_decay (float): regularization parameter for the optimizer; default:0.001\n",
       "| mode (string): 'multiclass': classification with multiple classes, 'multilabel': predicting several labels at the same time, 'binary':binary classification, 'regression': regression; default:'multiclass'\n",
       "| gsam_alpha (float): if higher than zero, uses GSAM instead of SAM for the optimizer\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns optimizer, learning rate scheduler, and loss criterion objects"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bored-quality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train, X_test, y_train, y_test, mode='classification',\n",
       ">                      feature_calc=False, return_features=False,\n",
       ">                      feature_set=['known', 'exhaustive'],\n",
       ">                      additional_features_train=None,\n",
       ">                      additional_features_test=None)\n",
       "\n",
       "wrapper function to train standard machine learning models on glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| X_train, X_test (list or dataframe): either lists of glycans (needs feature_calc = True) or motif dataframes such as from annotate_dataset\n",
       "| y_train, y_test (list): lists of labels\n",
       "| mode (string): 'classification' or 'regression'; default:'classification'\n",
       "| feature_calc (bool): set to True for calculating motifs from glycans; default:False\n",
       "| return_features (bool): whether to return calculated features; default:False\n",
       "| feature_set (list): which feature set to use for annotations, add more to list to expand; default:['known','exhaustive']; options are: 'known' (hand-crafted glycan features), 'graph' (structural graph features of glycans), and 'exhaustive' (all mono- and disaccharide features)\n",
       "| additional_features_train (dataframe): additional features (apart from glycans) to be used for training. Has to be of the same length as X_train; default:None\n",
       "| additional_features_test (dataframe): additional features (apart from glycans) to be used for evaluation. Has to be of the same length as X_test; default:None\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns trained model"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.8948863636363636\n"
     ]
    }
   ],
   "source": [
    "mammal = [1 if k == 'Mammalia' else 0 for k in df_species[df_species.Phylum=='Chordata'].Class.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Phylum=='Chordata'].target.values.tolist(), mammal)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['exhaustive'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "federal-lover",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model)\n",
       "\n",
       "plots relevant features for model prediction\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moved-greene",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model, X_test, y_test, n=10)\n",
       "\n",
       "analyzes misclassifications of trained machine learning model\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (model object): trained machine learning model from train_ml_model\n",
       "| X_test (dataframe): motif dataframe used for validating model\n",
       "| y_test (list): list of labels\n",
       "| n (int): number of returned misclassifications; default:10\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns tuples of misclassifications and their predicted probability"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gal(?1-?)[Neu5Gc(a2-?)]Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-3)[Gal(?1-?)[Neu5Gc(a2-?)]Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.5203443765640259),\n",
       " ('Gal3S(b1-3)[Fuc(a1-2)]Gal(b1-3)[GlcNAc(b1-6)]GalNAc', 0.5743801593780518),\n",
       " ('Gal1Cer3S', 0.7558071613311768),\n",
       " ('Man(a1-2)Man(a1-6)[Man(a1-3)]Man(a1-6)[Glc(a1-3)Man(a1-2)Man(a1-2)Man(a1-3)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.8287261128425598),\n",
       " ('Neu5Ac(a2-8)Neu5Ac(a2-3)Gal(b1-4)Glc1Cer', 0.6059761643409729),\n",
       " ('Neu5Ac(a2-3)[GalNAc(b1-4)]Gal(b1-3)[GlcNAc(b1-6)]GalNAc',\n",
       "  0.6028361916542053),\n",
       " ('GalNAc(b1-4)GlcNAc(b1-2)Man(a1-3)[Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8487561941146851),\n",
       " ('Neu5Ac(a2-3)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-?)[Gal(b1-4)GlcNAc(b1-2)Man(a1-?)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.7756061553955078),\n",
       " ('Fuc(a1-2)Gal(a1-3)Gal(a1-4)Gal(b1-3)[GlcNAc(b1-6)]GalNAc',\n",
       "  0.5661913156509399),\n",
       " ('Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-?)[Gal(b1-4)GlcNAc(b1-?)]Man(a1-3)[Man(a1-?)Man(a1-6)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.8166676163673401)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean-personality",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size, num_classes=1)\n",
       "\n",
       "given glycan graphs as input, predicts properties via a graph neural network\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| lib_size (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-arnold",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                    data_min=-11.355, data_max=23.892, input_size_prot=1280)\n",
       "\n",
       "given glycan graphs and protein representations as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): dimensionality of protein representations used as input; default:1280\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-passion",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco, hidden_size=128, num_classes=1,\n",
       ">                         data_min=-11.355, data_max=23.892,\n",
       ">                         input_size_prot=1000)\n",
       "\n",
       "given glycan graphs and protein sequences as input, predicts protein-glycan binding\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| input_size_glyco (int): number of unique tokens for graph nodes; usually len(lib)\n",
       "| hidden_size (int): layer size for the graph convolutions; default:128\n",
       "| num_classes (int): number of output classes; only >1 for multilabel classification; default:1\n",
       "| data_min (float): minimum observed value in training data; default: -11.355\n",
       "| data_max (float): maximum observed value in training data; default: 23.892\n",
       "| input_size_prot (int): maximum length of protein sequence for padding/cutting; default:1000\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "likely-grove",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "given an ESM1b representation of N and 20 AA up + downstream, predicts whether it's a sequon\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns batch-wise predictions"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-command",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model, mode='sparse', sparsity=0.1)\n",
       "\n",
       "initializes linear layers of PyTorch model with a weight initialization\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model (Pytorch object): neural network (such as SweetNet) for analyzing glycans\n",
       "| mode (string): which initialization algorithm; choices are 'sparse','kaiming','xavier';default:'sparse'\n",
       "| sparsity (float): proportion of sparsity after initialization; default:0.1 / 10%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collective-cooler",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type, num_classes, libr=None, trained=False)\n",
       "\n",
       "wrapper to instantiate model, initialize it, and put it on the GPU\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| model_type (string): string indicating the type of model\n",
       "| num_classes (int): number of unique classes for classification\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns PyTorch model object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesbian-closer",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list, labels, libr=None,\n",
       ">                         label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert a whole list of glycans into a graph dataset\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns list of node list / edge list / label list data tuples"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broadband-tours",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list, labels, libr=None, batch_size=32,\n",
       ">                             shuffle=True, drop_last=False, extra_feature=None,\n",
       ">                             label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert glycans and labels to a torch_geometric DataLoader\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| shuffle (bool): if samples should be shuffled when making dataloader; default:True\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dataloader object used for training deep learning models"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heated-georgia",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train, glycan_list_val, labels_train,\n",
       ">                           labels_val, libr=None, batch_size=32,\n",
       ">                           drop_last=False, extra_feature_train=None,\n",
       ">                           extra_feature_val=None, label_type=torch.int64)\n",
       "\n",
       "wrapper function to convert split training/test data into dictionary of dataloaders\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycan_list_train (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| glycan_list_val (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels_train (list): list of labels\n",
       "| labels_val (list): list of labels\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): how many samples should be in each batch; default:32\n",
       "| drop_last (bool): whether last batch is dropped; default:False\n",
       "| extra_feature_train (list): can be used to feed another input to the dataloader; default:None\n",
       "| extra_feature_val (list): can be used to feed another input to the dataloader; default:None\n",
       "| label_type (torch object): which tensor type for label, default is torch.long for binary labels, change to torch.float for continuous\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns a dictionary of dataloaders for training and testing deep learning models"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continued-tokyo",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans, model, libr=None, batch_size=32, rep=True,\n",
       ">                      class_list=None)\n",
       "\n",
       "Returns a dataframe of learned representations for a list of glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of glycans in IUPAC-condensed as strings\n",
       "| model (PyTorch object): trained graph neural network (such as SweetNet) for analyzing glycans\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| batch_size (int): change to batch_size used during training; default:32\n",
       "| rep (bool): True returns representations, False returns actual predicted labels; default is True\n",
       "| class_list (list): list of unique classes to map predictions\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of learned representations (columns) for each glycan (rows)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collective-strike",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot, glycans, model, prot_dic={},\n",
       ">                        background_correction=False, correction_df=None,\n",
       ">                        batch_size=128, libr=None, sort=True, flex=False)\n",
       "\n",
       "Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prot (string): protein amino acid sequence\n",
       "| glycans (list): list of glycans in IUPACcondensed\n",
       "| model (PyTorch object): trained LectinOracle-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "| background_correction (bool): whether to correct predictions for background; default:False\n",
       "| correction_df (dataframe): background prediction for (ideally) all provided glycans; default:V4 correction file\n",
       "| batch_size (int): change to batch_size used during training; default:128\n",
       "| libr (list): sorted list of unique glycoletters observed in the glycans of our dataset\n",
       "| sort (bool): whether to sort prediction results descendingly; default:True\n",
       "| flex (bool): depends on whether you use LectinOracle (False) or LectinOracle_flex (True); default:False\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of glycan sequences and predicted binding to prot"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "therapeutic-alias",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots, model, prot_dic)\n",
       "\n",
       "Predicts whether an N-sequon will be glycosylated\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings), in the form of 20 AA + N + 20 AA; replace missing sequence with corr. number of 'z'\n",
       "| model (PyTorch object): trained NSequonPred-type model\n",
       "| prot_dic (dictionary): dictionary of type protein sequence:ESM1b representation\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dataframe of protein sequences and predicted likelihood of being an N-sequon"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cognitive-diploma",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots, model, alphabet)\n",
       "\n",
       "Retrieves ESM1b representations of protein for using them as input for LectinOracle\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| prots (list): list of protein sequences (strings) that should be converted\n",
       "| model (ESM1b object): trained ESM1b model; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "| alphabet (ESM1b object): used for converting sequences; from running esm.pretrained.esm1b_t33_650M_UR50S()\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns dictionary of the form protein sequence:ESM1b representation"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "checked-effect",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in, rank='Domain', min_seq=5, wildcard_seed=False,\n",
       ">                        wildcard_list=None, wildcard_name=None, r=0.1,\n",
       ">                        col='target')\n",
       "\n",
       "stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df_in (dataframe): dataframe of glycan sequences and taxonomic labels\n",
       "| rank (string): which rank should be filtered; default:'domain'\n",
       "| min_seq (int): how many glycans need to be present in class to keep it; default:5\n",
       "| wildcard_seed (bool): set to True if you want to seed wildcard glycoletters; default:False\n",
       "| wildcard_list (list): list which glycoletters a wildcard encompasses\n",
       "| wildcard_name (string): how the wildcard should be named in the IUPAC-condensed nomenclature\n",
       "| r (float): rate of replacement, default:0.1 or 10%\n",
       "| col (string): column name for glycan sequences; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns train_x, val_x (lists of glycans (strings) after stratified shuffle split)\n",
       "| train_y, val_y (lists of taxonomic labels (mapped integers))\n",
       "| id_val (taxonomic labels in text form (strings))\n",
       "| class_list (list of unique taxonomic classes (strings))\n",
       "| class_converter (dictionary to map mapped integers back to text labels)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Galf(a1-4)GalNAc(b1-4)Rha2Ac3Ac(a1-3)GlcNAc', 'GlcNAc(b1-3)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-3)Gal(b1-4)Glc1Cer', 'Araf(a1-2)Xyl(a1-6)[Glc(b1-4)]Glc(b1-4)Glc(b1-4)Glc-ol', 'Neu5Ac(a2-3)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-3)Gal(b1-4)GlcNAc(b1-3)Gal', 'Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-?)[Gal(b1-4)GlcNAc(b1-?)]Man(a1-3)[Man(a1-?)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'Man(a1-3)[Xyl(b1-2)][Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-3)]GlcNAc-ol', 'Neu4Ac(a2-3)Gal(b1-4)Glc-ol', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAcOS(b1-2)Man(a1-3)[GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Fuc(a1-?)[Gal(b1-?)]GlcNAc(b1-2)[Fuc(a1-?)[Gal(b1-?)]GlcNAc(b1-?)]Man(a1-?)[Fuc(a1-?)[Gal(b1-?)]GlcNAc(b1-2)Man(a1-?)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(a1-6)Glc(a1-2)Fruf']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ordinary-balance",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans, labels, test_size=0.2)\n",
       "\n",
       "splits glycans and labels into train / test sets\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| glycans (list): list of IUPAC-condensed glycan sequences as strings\n",
       "| labels (list): list of labels used for prediction\n",
       "| test_size (float): % size of test set; default:0.2 / 20%\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| Returns X_train, X_test, y_train, y_test"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Neu5Gc(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Gal(b1-4)GlcNAc', 'GalA(a1-3)Glc(a1-5)Kdo', '[Man(a1-2)Man(a1-2)Man(a1-2)]Man(a1-6)Man', 'Neu5Ac(a2-6)Gal(b1-4)GlcNAcOS(b1-2)Man(a1-3)[Neu5Ac(a2-6)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'HexNAc(?1-?)[Fuc(a1-?)]GlcNAc(b1-2)Man(a1-3)[Fuc(a1-?)[HexNAc(?1-?)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'ManNAc(a1-3)Gal(b1-4)LDManHep(a1-5)KdoOP', 'GalNAc(a1-3)[GlcNAc(a1-4)]GalNAc(a1-4)Glc(a1-4)Gal(b1-3)GalNAc', 'Gal(b1-?)GlcNAc(b1-6)[GlcNAc(b1-3)]GalNAc', 'Glc(b1-4)Glc(b1-4)Glc(b1-3)Gal']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.target.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flush-joyce",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df, rank='Species', glycan_col='target')\n",
       "\n",
       "converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations\n",
       "\n",
       "| Arguments:\n",
       "| :-\n",
       "| df (dataframe): dataframe where each row is one glycan - species association\n",
       "| rank (string): which label column should be used; default:Species\n",
       "| glycan_col (string): column name of where the glycan sequences are stored; default:target\n",
       "\n",
       "| Returns:\n",
       "| :-\n",
       "| (1) list of unique glycans in df\n",
       "| (2) list of lists, where each inner list are all the labels of a glycan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
